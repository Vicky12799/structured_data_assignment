{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d15483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incident'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e2744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d665f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data, replace this with your actual data\n",
    "data = df\n",
    "\n",
    "# Filter positive and negative sets based on the criteria\n",
    "positive_set = data[data['Incident'] == 'TARGET DRUG']\n",
    "negative_set = data[data['Incident'] != 'TARGET DRUG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75858987",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930033ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dbefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency-based features\n",
    "freq_features = data.groupby('Patient-Uid')['Incident'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Reset the index before creating the feature\n",
    "data_reset_index = data.reset_index(drop=True)\n",
    "\n",
    "# Calculate the time since the last incident for each patient\n",
    "data_reset_index['Days_since_last_incident'] = data_reset_index.groupby('Patient-Uid')['Date'].diff().dt.days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcaa968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([freq_features, data_reset_index[['Days_since_last_incident']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efe75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reset_index.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50116f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0384bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a812642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Combine features and labels for modeling\n",
    "X = pd.concat([freq_features, data_reset_index[['Days_since_last_incident']]], axis=1)\n",
    "y = data['Incident'].apply(lambda x: 1 if x == 'TARGET DRUG' else 0)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37027eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the shapes of X and y before model training\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Ensure that X and y have the same number of samples\n",
    "if X.shape[0] != y.shape[0]:\n",
    "    raise ValueError(\"Inconsistent number of samples between X and y.\")\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba774db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('train.csv')  # Replace with your data file\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Filter positive and negative sets based on the criteria\n",
    "positive_set = data[data['Incident'] == 'TARGET DRUG']\n",
    "negative_set = data[data['Incident'] != 'TARGET DRUG']\n",
    "\n",
    "# Feature Engineering\n",
    "# Frequency-based features\n",
    "freq_features = data.groupby('Patient-Uid')['Incident'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Time-based features\n",
    "data_reset_index = data.reset_index(drop=True)\n",
    "data_reset_index['Days_since_last_incident'] = data_reset_index.groupby('Patient-Uid')['Date'].diff().dt.days\n",
    "\n",
    "# Combine features and labels for modeling\n",
    "X = pd.concat([freq_features, data_reset_index[['Days_since_last_incident']]], axis=1)\n",
    "y = data['Incident'].apply(lambda x: 1 if x == 'TARGET DRUG' else 0)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('test_data.csv')  # Replace with your test data file\n",
    "\n",
    "# Feature Engineering for test data\n",
    "test_freq_features = test_data.groupby('Patient-Uid')['Incident'].value_counts().unstack().fillna(0)\n",
    "test_data_reset_index = test_data.reset_index(drop=True)\n",
    "test_data_reset_index['Days_since_last_incident'] = test_data_reset_index.groupby('Patient-Uid')['Date'].diff().dt.days\n",
    "test_X = pd.concat([test_freq_features, test_data_reset_index[['Days_since_last_incident']]], axis=1)\n",
    "\n",
    "# Predict using the trained model\n",
    "test_predictions = model.predict(test_X)\n",
    "test_data['Predicted'] = test_predictions\n",
    "\n",
    "# Save the predictions\n",
    "test_data[['Patient-Uid', 'Predicted']].to_csv('final_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76e9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('train.csv')  # Replace with your data file\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Filter positive and negative sets based on the criteria\n",
    "positive_set = data[data['Incident'] == 'TARGET DRUG']\n",
    "negative_set = data[data['Incident'] != 'TARGET DRUG']\n",
    "\n",
    "# Feature Engineering\n",
    "# Frequency-based features\n",
    "freq_features = data.groupby('Patient-Uid')['Incident'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Time-based features\n",
    "data.reset_index(drop=True,inplace =True)\n",
    "data['Days_since_last_incident'] = data.groupby('Patient-Uid')['Date'].diff().dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27deed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa771910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a828bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and labels for modeling\n",
    "X = pd.concat([freq_features, data[['Days_since_last_incident']]], axis=1)\n",
    "y = data['Incident'].apply(lambda x: 1 if x == 'TARGET DRUG' else 0)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('test_data.csv')  # Replace with your test data file\n",
    "\n",
    "# Feature Engineering for test data\n",
    "test_freq_features = test_data.groupby('Patient-Uid')['Incident'].value_counts().unstack().fillna(0)\n",
    "test_data_reset_index = test_data.reset_index(drop=True)\n",
    "test_data_reset_index['Days_since_last_incident'] = test_data_reset_index.groupby('Patient-Uid')['Date'].diff().dt.days\n",
    "test_X = pd.concat([test_freq_features, test_data_reset_index[['Days_since_last_incident']]], axis=1)\n",
    "\n",
    "# Predict using the trained model\n",
    "test_predictions = model.predict(test_X)\n",
    "test_data['Predicted'] = test_predictions\n",
    "\n",
    "# Save the predictions\n",
    "test_data[['Patient-Uid', 'Predicted']].to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e6b942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Patient-Uid</th>\n",
       "      <th>Date</th>\n",
       "      <th>Incident</th>\n",
       "      <th>Days_since_last_incident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2369750</th>\n",
       "      <td>17979391</td>\n",
       "      <td>a0eccd46-1c7c-11ec-ae76-16262ee38c7f</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>DRUG_TYPE_7</td>\n",
       "      <td>860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077673</th>\n",
       "      <td>2965724</td>\n",
       "      <td>a0ed6093-1c7c-11ec-b60c-16262ee38c7f</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>PRIMARY_DIAGNOSIS</td>\n",
       "      <td>754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544727</th>\n",
       "      <td>2820776</td>\n",
       "      <td>a0e8490e-1c7c-11ec-899b-16262ee38c7f</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>PRIMARY_DIAGNOSIS</td>\n",
       "      <td>-405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033070</th>\n",
       "      <td>25083019</td>\n",
       "      <td>a0ec0c35-1c7c-11ec-bd1c-16262ee38c7f</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>DRUG_TYPE_2</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307033</th>\n",
       "      <td>16805885</td>\n",
       "      <td>a0ef063e-1c7c-11ec-953f-16262ee38c7f</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>DRUG_TYPE_1</td>\n",
       "      <td>-779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489960</th>\n",
       "      <td>19470379</td>\n",
       "      <td>a0ed5970-1c7c-11ec-ba66-16262ee38c7f</td>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>DRUG_TYPE_1</td>\n",
       "      <td>467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952906</th>\n",
       "      <td>1241558</td>\n",
       "      <td>a0ead868-1c7c-11ec-984b-16262ee38c7f</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>PRIMARY_DIAGNOSIS</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255211</th>\n",
       "      <td>15364579</td>\n",
       "      <td>a0ea7a21-1c7c-11ec-9b3b-16262ee38c7f</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>DRUG_TYPE_1</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497432</th>\n",
       "      <td>2734169</td>\n",
       "      <td>a0e59366-1c7c-11ec-bd5d-16262ee38c7f</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>DRUG_TYPE_1</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807091</th>\n",
       "      <td>1478177</td>\n",
       "      <td>a0e45697-1c7c-11ec-a175-16262ee38c7f</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>DRUG_TYPE_8</td>\n",
       "      <td>-1096.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                           Patient-Uid       Date  \\\n",
       "2369750    17979391  a0eccd46-1c7c-11ec-ae76-16262ee38c7f 2020-06-17   \n",
       "2077673     2965724  a0ed6093-1c7c-11ec-b60c-16262ee38c7f 2020-02-05   \n",
       "1544727     2820776  a0e8490e-1c7c-11ec-899b-16262ee38c7f 2015-12-08   \n",
       "3033070    25083019  a0ec0c35-1c7c-11ec-bd1c-16262ee38c7f 2019-06-25   \n",
       "2307033    16805885  a0ef063e-1c7c-11ec-953f-16262ee38c7f 2016-03-16   \n",
       "...             ...                                   ...        ...   \n",
       "2489960    19470379  a0ed5970-1c7c-11ec-ba66-16262ee38c7f 2019-12-09   \n",
       "1952906     1241558  a0ead868-1c7c-11ec-984b-16262ee38c7f 2019-04-15   \n",
       "2255211    15364579  a0ea7a21-1c7c-11ec-9b3b-16262ee38c7f 2019-09-26   \n",
       "1497432     2734169  a0e59366-1c7c-11ec-bd5d-16262ee38c7f 2015-10-27   \n",
       "807091      1478177  a0e45697-1c7c-11ec-a175-16262ee38c7f 2015-08-21   \n",
       "\n",
       "                  Incident  Days_since_last_incident  \n",
       "2369750        DRUG_TYPE_7                     860.0  \n",
       "2077673  PRIMARY_DIAGNOSIS                     754.0  \n",
       "1544727  PRIMARY_DIAGNOSIS                    -405.0  \n",
       "3033070        DRUG_TYPE_2                     399.0  \n",
       "2307033        DRUG_TYPE_1                    -779.0  \n",
       "...                    ...                       ...  \n",
       "2489960        DRUG_TYPE_1                     467.0  \n",
       "1952906  PRIMARY_DIAGNOSIS                     629.0  \n",
       "2255211        DRUG_TYPE_1                     -56.0  \n",
       "1497432        DRUG_TYPE_1                      46.0  \n",
       "807091         DRUG_TYPE_8                   -1096.0  \n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=data.sample(n=2700,random_state=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9683b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_9800\\2985918114.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  sample_mean=sample.mean(axis=0)\n",
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_9800\\2985918114.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  sample_mean=sample.mean(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  8.138134e+06\n",
       "Days_since_last_incident    3.182667e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mean=sample.mean(axis=0)\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_9800\\1684176108.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  population_mean=data.mean(axis = 0)\n"
     ]
    }
   ],
   "source": [
    "population_mean=data.mean(axis = 0)\n",
    "population_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff84ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bce875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
